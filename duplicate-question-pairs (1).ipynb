{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1519,"sourceType":"datasetVersion","datasetId":826}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:20:04.425066Z","iopub.execute_input":"2025-10-06T13:20:04.425390Z","iopub.status.idle":"2025-10-06T13:20:04.939942Z","shell.execute_reply.started":"2025-10-06T13:20:04.425360Z","shell.execute_reply":"2025-10-06T13:20:04.938863Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/first-quora-dataset/q_quora.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\n\nfile_path = \"/kaggle/input/first-quora-dataset/q_quora.csv\"\n\n\ndf = pd.read_csv(file_path, low_memory=False)\n\n\n\nprint(df.head())\nprint(df.info())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:20:04.941428Z","iopub.execute_input":"2025-10-06T13:20:04.942031Z","iopub.status.idle":"2025-10-06T13:20:07.825923Z","shell.execute_reply.started":"2025-10-06T13:20:04.941995Z","shell.execute_reply":"2025-10-06T13:20:07.824960Z"}},"outputs":[{"name":"stdout","text":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2 is_duplicate Unnamed: 6  \\\n0  What is the step by step guide to invest in sh...            0        NaN   \n1  What would happen if the Indian government sto...            0        NaN   \n2  How can Internet speed be increased by hacking...            0        NaN   \n3  Find the remainder when [math]23^{24}[/math] i...            0        NaN   \n4            Which fish would survive in salt water?            0        NaN   \n\n  Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  Unnamed: 12  \n0        NaN        NaN        NaN         NaN         NaN          NaN  \n1        NaN        NaN        NaN         NaN         NaN          NaN  \n2        NaN        NaN        NaN         NaN         NaN          NaN  \n3        NaN        NaN        NaN         NaN         NaN          NaN  \n4        NaN        NaN        NaN         NaN         NaN          NaN  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 404351 entries, 0 to 404350\nData columns (total 13 columns):\n #   Column        Non-Null Count   Dtype  \n---  ------        --------------   -----  \n 0   id            404351 non-null  int64  \n 1   qid1          404351 non-null  int64  \n 2   qid2          404351 non-null  int64  \n 3   question1     404350 non-null  object \n 4   question2     404349 non-null  object \n 5   is_duplicate  404351 non-null  object \n 6   Unnamed: 6    337 non-null     object \n 7   Unnamed: 7    27 non-null      object \n 8   Unnamed: 8    8 non-null       object \n 9   Unnamed: 9    3 non-null       object \n 10  Unnamed: 10   2 non-null       object \n 11  Unnamed: 11   2 non-null       object \n 12  Unnamed: 12   2 non-null       float64\ndtypes: float64(1), int64(3), object(9)\nmemory usage: 40.1+ MB\nNone\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom multiprocessing import Pool, cpu_count\nimport pandas as pd\n\n\nstop_words = set(stopwords.words(\"english\"))\nk = WordNetLemmatizer()\npattern = re.compile(f\"[{re.escape(string.punctuation)}]\")\n\ndef textpreprocessing(text):\n    if not isinstance(text, str):\n        return \"\"\n    \n    text = pattern.sub(\"\", text.lower())\n    n = [token for token in text.split() if token not in stop_words]\n    text = \" \".join(n)\n    \n    u = [k.lemmatize(token) for token in text.split()]\n    text = \" \".join(u)\n    return text\n\n\ndef apply_series(series):\n    return series.apply(textpreprocessing)\n\n\ndef parallel_apply(series):\n    n_cores = cpu_count()\n    chunk_size = int(len(series) / n_cores) + 1\n    chunks = [series[i:i + chunk_size] for i in range(0, len(series), chunk_size)]\n    \n    with Pool(n_cores) as pool:\n        results = pool.map(apply_series, chunks)\n    \n    return pd.concat(results)\n\n\ndf['question1'] = parallel_apply(df['question1'])\ndf['question2'] = parallel_apply(df['question2'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:20:07.828045Z","iopub.execute_input":"2025-10-06T13:20:07.828397Z","iopub.status.idle":"2025-10-06T13:20:35.489742Z","shell.execute_reply.started":"2025-10-06T13:20:07.828375Z","shell.execute_reply":"2025-10-06T13:20:35.488510Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"sentences1=[q.split() for q in df['question1']]\nsentences2=[q.split() for q in df['question2']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:20:35.491096Z","iopub.execute_input":"2025-10-06T13:20:35.491886Z","iopub.status.idle":"2025-10-06T13:20:37.990160Z","shell.execute_reply.started":"2025-10-06T13:20:35.491828Z","shell.execute_reply":"2025-10-06T13:20:37.988795Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nfrom gensim.models import Word2Vec\nmodel1=Word2Vec(sentences1,vector_size=200,sg=1,min_count=1,workers=4)\nmodel2=Word2Vec(sentences2,vector_size=200,sg=1,min_count=1,workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:20:37.991309Z","iopub.execute_input":"2025-10-06T13:20:37.991631Z","iopub.status.idle":"2025-10-06T13:22:37.304913Z","shell.execute_reply.started":"2025-10-06T13:20:37.991600Z","shell.execute_reply":"2025-10-06T13:22:37.303935Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()                \n    text = ''.join(ch for ch in text if ch.isalnum() or ch.isspace()) \n    return text\n\n\ndf['question1'] = df['question1'].astype(str).apply(clean_text)\ndf['question2'] = df['question2'].astype(str).apply(clean_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:22:37.305993Z","iopub.execute_input":"2025-10-06T13:22:37.306593Z","iopub.status.idle":"2025-10-06T13:22:40.549618Z","shell.execute_reply.started":"2025-10-06T13:22:37.306559Z","shell.execute_reply":"2025-10-06T13:22:40.548437Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nvocab={}\ni=1\nfor w in model1.wv.index_to_key:\n    vocab[w]=i\n    i+=1\nvocab_size=len(vocab)+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:22:40.550724Z","iopub.execute_input":"2025-10-06T13:22:40.551147Z","iopub.status.idle":"2025-10-06T13:22:57.768284Z","shell.execute_reply.started":"2025-10-06T13:22:40.551122Z","shell.execute_reply":"2025-10-06T13:22:57.767083Z"}},"outputs":[{"name":"stderr","text":"2025-10-06 13:22:42.267827: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759756962.489026      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759756962.553616      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"vocab_size\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:22:57.769343Z","iopub.execute_input":"2025-10-06T13:22:57.770154Z","iopub.status.idle":"2025-10-06T13:22:57.777782Z","shell.execute_reply.started":"2025-10-06T13:22:57.770125Z","shell.execute_reply":"2025-10-06T13:22:57.776767Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"75688"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def text_to_sequences(sentence, vocab):\n    seq = []\n    for w in sentence.split():\n        if w in vocab:\n            seq.append(vocab[w])   \n    return seq\n\nseq1 = []\nfor q in df['question1']:\n    seq1.append(text_to_sequences(q, vocab))\n\nseq2 = []\nfor q in df['question2']:\n    seq2.append(text_to_sequences(q, vocab))\nx1=pad_sequences(seq1,maxlen=30,padding='post')\nx2=pad_sequences(seq2,maxlen=30,padding='post')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:22:57.780404Z","iopub.execute_input":"2025-10-06T13:22:57.780691Z","iopub.status.idle":"2025-10-06T13:23:02.873053Z","shell.execute_reply.started":"2025-10-06T13:22:57.780671Z","shell.execute_reply":"2025-10-06T13:23:02.872090Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"x1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:23:02.874292Z","iopub.execute_input":"2025-10-06T13:23:02.874602Z","iopub.status.idle":"2025-10-06T13:23:02.882306Z","shell.execute_reply.started":"2025-10-06T13:23:02.874580Z","shell.execute_reply":"2025-10-06T13:23:02.881286Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([[ 560,  560, 2074, ...,    0,    0,    0],\n       [ 232, 9764, 9764, ...,    0,    0,    0],\n       [ 133,  357,  254, ...,    0,    0,    0],\n       ...,\n       [   9, 1709,    0, ...,    0,    0,    0],\n       [6581, 2868,  199, ...,    0,    0,    0],\n       [   4,   82, 3430, ...,    0,    0,    0]], dtype=int32)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dense, concatenate\n\nembedding_dim = 200\nmax_len = 30\n\n\nembedding_matrix = np.zeros((len(vocab) + 1, embedding_dim))\n\nfor word, i in vocab.items():\n    if word in model1.wv:\n        embedding_matrix[i] = model1.wv[word]  \n\n\nembedding_layer = Embedding(\n    input_dim=len(vocab) + 1,\n    output_dim=embedding_dim,\n    weights=[embedding_matrix],\n    trainable=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:23:02.883356Z","iopub.execute_input":"2025-10-06T13:23:02.883618Z","iopub.status.idle":"2025-10-06T13:23:03.585142Z","shell.execute_reply.started":"2025-10-06T13:23:02.883596Z","shell.execute_reply":"2025-10-06T13:23:03.584095Z"}},"outputs":[{"name":"stderr","text":"2025-10-06 13:23:03.242374: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"\ndf['is_duplicate'] = pd.to_numeric(df['is_duplicate'], errors='coerce')\n\n\ndf = df[df['is_duplicate'].notna()]\ndf['is_duplicate'] = df['is_duplicate'].astype(int)\n\n\ndef text_to_sequences(sentence, vocab):\n    seq = []\n    for w in sentence.split():\n        if w in vocab:\n            seq.append(vocab[w])\n    return seq\n\nseq1 = [text_to_sequences(q, vocab) for q in df['question1']]\nseq2 = [text_to_sequences(q, vocab) for q in df['question2']]\n\n\nx1 = pad_sequences(seq1, maxlen=30, padding='post')\nx2 = pad_sequences(seq2, maxlen=30, padding='post')\n\n\ny = df['is_duplicate'].values\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:23:03.586073Z","iopub.execute_input":"2025-10-06T13:23:03.586340Z","iopub.status.idle":"2025-10-06T13:23:09.099083Z","shell.execute_reply.started":"2025-10-06T13:23:03.586321Z","shell.execute_reply":"2025-10-06T13:23:09.098095Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Dropout, Lambda\nfrom keras.models import Model\nfrom keras.preprocessing.sequence import pad_sequences\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:23:09.099971Z","iopub.execute_input":"2025-10-06T13:23:09.100212Z","iopub.status.idle":"2025-10-06T13:23:09.109338Z","shell.execute_reply.started":"2025-10-06T13:23:09.100193Z","shell.execute_reply":"2025-10-06T13:23:09.108143Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"x1_train, x1_test, x2_train, x2_test, y_train, y_test = train_test_split(\n    x1, x2, y, test_size=0.2, random_state=42\n)\nq1_in = Input(shape=(30,))\nq2_in = Input(shape=(30,))\n\n\nq1_embed = embedding_layer(q1_in)\nq2_embed = embedding_layer(q2_in)\n\n\nshared_lstm = Bidirectional(LSTM(64, return_sequences=False))\n\nq1_vec = shared_lstm(q1_embed)\nq2_vec = shared_lstm(q2_embed)\n\n\ndiff = Lambda(lambda x: abs(x[0] - x[1]))([q1_vec, q2_vec])\nmerged = Dense(128, activation='relu',kernel_regularizer='l2')(diff)\nmerged = Dropout(0.5)(merged)\n\n\nout = Dense(1, activation='sigmoid')(merged)\n\nmodel = Model(inputs=[q1_in, q2_in], outputs=out)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:23:09.110644Z","iopub.execute_input":"2025-10-06T13:23:09.111047Z","iopub.status.idle":"2025-10-06T13:23:09.359972Z","shell.execute_reply.started":"2025-10-06T13:23:09.111022Z","shell.execute_reply":"2025-10-06T13:23:09.358981Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\nmodel.fit([x1_train, x2_train], y_train,\n          validation_data=([x1_test, x2_test], y_test),\n          epochs=20, batch_size=512, callbacks=[es],\n          class_weight={0:1, 1:2})\n\n\n\nloss, acc = model.evaluate([x1_test, x2_test], y_test)\nprint(\"Test Accuracy:\", acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T13:23:09.360915Z","iopub.execute_input":"2025-10-06T13:23:09.361185Z","iopub.status.idle":"2025-10-06T13:56:49.796253Z","shell.execute_reply.started":"2025-10-06T13:23:09.361145Z","shell.execute_reply":"2025-10-06T13:56:49.795167Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 312ms/step - accuracy: 0.6664 - loss: 1.0908 - val_accuracy: 0.7466 - val_loss: 0.5084\nEpoch 2/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 307ms/step - accuracy: 0.7549 - loss: 0.6478 - val_accuracy: 0.7665 - val_loss: 0.4809\nEpoch 3/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 306ms/step - accuracy: 0.7760 - loss: 0.6085 - val_accuracy: 0.7650 - val_loss: 0.4878\nEpoch 4/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 310ms/step - accuracy: 0.7894 - loss: 0.5826 - val_accuracy: 0.7933 - val_loss: 0.4438\nEpoch 5/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 308ms/step - accuracy: 0.8019 - loss: 0.5617 - val_accuracy: 0.7909 - val_loss: 0.4507\nEpoch 6/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 309ms/step - accuracy: 0.8116 - loss: 0.5393 - val_accuracy: 0.7920 - val_loss: 0.4498\nEpoch 7/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 308ms/step - accuracy: 0.8178 - loss: 0.5240 - val_accuracy: 0.8102 - val_loss: 0.4208\nEpoch 8/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 312ms/step - accuracy: 0.8273 - loss: 0.5052 - val_accuracy: 0.7966 - val_loss: 0.4462\nEpoch 9/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 314ms/step - accuracy: 0.8320 - loss: 0.4930 - val_accuracy: 0.8085 - val_loss: 0.4248\nEpoch 10/20\n\u001b[1m632/632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 315ms/step - accuracy: 0.8401 - loss: 0.4762 - val_accuracy: 0.8060 - val_loss: 0.4346\n\u001b[1m2526/2526\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 18ms/step - accuracy: 0.8072 - loss: 0.4245\nTest Accuracy: 0.8102298378944397\n","output_type":"stream"}],"execution_count":15}]}